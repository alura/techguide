# Data Science
## Nivel 1
- [ ] **Ciência de Dados - Fundamentos**:
   - A Ciência de Dados é o ato de utilizar algoritmos e sistemas para extrair, organizar e analisar dados a partir de diversas fontes, a fim de detectar padrões e tomar decisões de negócios. As áreas de aplicação são infindáveis, como em negócios, biologia, medicina, engenharia, etc.
   - Conhecer o conceito de Exploração de Dados
   - Conhecer as principais funções, como 'describe', 'info', etc
   - Entender o papel de visualizações como histogramas e boxplots
   - Saber o que são variáveis categóricas nominais e ordinais
   - Explorar os dados em Python com as bibliotecas Pandas, Matplotlib, Seaborn e Numpy
- [ ] **Feature Engineering**:
   - Feature Engineering (Engenharia de atributos/características) refere-se ao processo de usar o conhecimento de domínio para selecionar e transformar as variáveis mais relevantes dos dados brutos ao criar um modelo preditivo usando aprendizado de máquina ou modelagem estatística, a fim de melhorar o desempenho dos algoritmos de aprendizado de máquina.
   - Gerar novas variáveis a partir dos dados disponíveis
   - Transformar dados brutos em características
   - Realçar os problemas dos modelos preditivos
   - Melhorar a precisão do modelo para novos dados
   - Selecionar e criar features utilizando as bibliotecas Pandas e Scikit-learn
- [ ] **Extração e Tratamento de Dados**:
   - A extração de dados é o processo de coleta ou recuperação de tipos diferentes de dados de uma variedade de fontes, muitos dos quais podem estar mal organizados ou completamente desestruturados.
   - Obter os dados que serão analisados
   - Tratar os dados obtidos, transformando-os, alterando sua estrutura e valores a fim de deixar a base de dados mais coerente e garantir que os dados que serão trabalhados estejam nas melhores condições para serem analisados
   - Utilizar as bibliotecas Pandas e Scikit-learn para tratar os dados
- [ ] **Python para Ciência de Dados**:
   - Python é uma linguagem de programação interpretada de alto nível e que suporta múltiplos paradigmas de programação, como imperativo, orientado a objetos e funcional. É uma linguagem com tipagem dinâmica e gerenciamento automático de memória.
   - Aprender lógica de programação em Python
   - Aprenda os fundamentos da linguagem como variáveis, funções, listas, condicionais e imports
   - Criar análises de dados
   - Utilizar o Matplotlib para gerar gráficos
   - Usar e manipular listas para agrupar dados
   - Conhecer a biblioteca NumPy
   - Conhecer a biblioteca Pandas
- [ ] **Jupyter & Colab notebooks**:
   - Jupyter Notebook e Google Colaboratory são Notebooks que permitem a criação de blocos de texto e blocos de código
   - Os Notebooks facilitam a elaboração de projetos de Data Science por ser possível visualizar o resultado da execução logo após o trecho de código
   - O Google Colaboratory permite escrever e executar códigos Python diretamente no navegador, sem nenhuma ou poucas configurações necessárias
   - Essas ferramentas facilitam o compartilhamento de projetos entre o time
- [ ] **R para Ciência de Dados**:
   - R é uma linguagem de programação comumente usada em estatística computacional e análise de dados.
   - Aprender a analisar, limpar e visualizar dados
   - Elaborar gráficos
   - Juntar bancos de dados
   - Tirar sumários estatísticos
   - Aprender modelos preditivos no R
- [ ] **Estatística e Matemática - Fundamentos**:
   - Equações, funções e limites
   - Logaritmos
   - Matrizes, determinantes, vetores e espaço vetorial
   - Derivadas e integrais
   - Diferença entre média, mediana e moda
   - Distribuição de frequência
   - Variância e desvio padrão
   - Distribuição binomial, poisson e normal
   - Nível e intervalo de confiança
   - Técnicas de amostragem
   - Regressão linear
   - Séries temporais
- [ ] **Visualização de Dados**:
   - A visualização de dados é uma expressão contemporânea da comunicação visual que consiste na representação visual de dados.
   - Mapear dados abstratos em representações visuais
   - Representar visualmente os dados que estão presentes no nosso mundo real
   - Usar Python, Matplotlib and Seaborn para gerar visualizações de dados
## Nivel 2
- [ ] **Machine Learning - Fundamentos**:
   - O Aprendizado de Máquina ou Machine Learning é um subcampo da Engenharia e da Ciência da Computação que evoluiu do estudo de reconhecimento de padrões e da teoria do aprendizado computacional em inteligência artificial.
   - Aprendizado supervisionado
   - Utilizar algoritmos de classificação
   - Utilizar algoritmos de regressão
   - Utilizar o Scikit-learn para criar modelos de machine learning
- [ ] **Machine Learning - Aprendizado Não Supervisionado**:
   - O Aprendizado Não Supervisionado utiliza algoritmos de Aprendizado de Máquina para analisar e agrupar conjuntos de dados não rotulados. Estes algoritmos descobrem padrões ocultos ou agrupamentos de dados sem a necessidade de intervenção humana.
   - O clustering ou análise de agrupamento de dados é o conjunto de técnicas de prospecção de dados (data mining) que visa fazer agrupamentos automáticos de dados segundo o seu grau de semelhança.
   - Conhecer a análise exploratória
   - Utilizar os métodos K-means, DBSCAN e Mean shift para agrupar dados sem classificação
   - Avaliar a qualidade de uma clusterização
   - Parametrizar métodos de clusterização através do máximo coeficiente de silhueta
   - Entender a matemática por trás das métricas de validação Silhouette, Davies Bouldin e Calinski Harabasz
   - Conhecer técnicas de redução de dimensionalidade
- [ ] **Machine Learning - Avaliação de Modelos**:
   - A Avaliação de Modelos é o processo que utiliza métricas para nos ajudar a analisar se um modelo treinado terá um bom desempenho de previsão quando exposto a novos conjuntos de dados.
   - Conhecer diferentes estratégias de avaliação e otimização de modelos
   - Utilizar um pipeline para treino e validação
   - Conhecer as principais métricas de avaliação de modelos de machine learning
- [ ] **SQL - Fundamentos**:
   - SQL (Structured Query Language, traduzindo, Linguagem de Consulta Estruturada) é uma linguagem de programação padronizada que é usada para gerenciar bancos de dados relacionais e realizar várias operações sobre os dados neles contidos.
   - Conhecer os comandos mais comuns do SQL
   - Usar SELECT para consultar uma tabela
   - Usar INSERT para inserir dados em uma tabela
   - Usar UPDATE para atualizar uma tabela
   - Usar DELETE para remover dados de uma tabela
   - Usar JOIN para conectar os dados de múltiplas tabelas
   - Conhecer as cláusulas (FROM, ORDER BY, etc)
- [ ] **Web Scraping**:
   - Web scraping ou raspagem de dados na web é a extração de dados de websites.
   - Usar o BeautifulSoup e Python para coletar dados
   - Pesquisar e navegar no HTML
   - Acessar o conteúdo e atributos das tags HTML
   - Construir datasets com os resultados das raspagens
- [ ] **Testes Estatísticos**:
   - Testes estatísticos são usados para examinar as relações entre as variáveis e as hipóteses de teste.
   - Criar intervalos de confiança para amostras
   - Comparar grupos de amostras
   - Executar testes estatísticos
   - Planejar experimentos para a coleta de dados
   - Propor modelos matemáticos para entender um dado problema
   - Construir mapas de cores para auxiliar a interpretação dos dados
## Nivel 3
- [ ] **Deep Learning**:
   - Deep Learning é um ramo de Machine Learning baseado em um conjunto de algoritmos que tentam modelar abstrações de alto nível de dados usando um grafo profundo com várias camadas de processamento, compostas de várias transformações lineares e não lineares.
   - Construir e treinar modelos com Keras
   - Construir e treinar modelos com Tensorflow
   - Selecionar as camadas de um modelo
   - Classificar imagens
   - Entender os conceitos de pesos e vieses
   - Redes neurais para regressão
   - Entender o conceito de Redes recorrentes
- [ ] **Aprendizado por Reforço**:
   - O Aprendizado por Reforço é uma área de Machine Learning que se preocupa com a forma como agentes inteligentes devem tomar medidas num ambiente, a fim de maximizar a noção de recompensa cumulativa.
   - Entender os conceitos de agente e recompensa
   - Entender a diferença entre reforço positivo e negativo
   - Conhecer o modelo Markov Decision Process
   - Entender o conceito de Retorno
   - Utilizar o algoritmo Q-learning
- [ ] **Visão Computacional**:
   - Visão Computacional é um campo científico interdisciplinar que lida com a forma como os computadores podem ganhar conhecimentos de alto nível a partir de imagens ou vídeos digitais. Da perspectiva da engenharia, procura compreender e automatizar tarefas que o sistema visual humano pode fazer.
   - Extrair regiões de interesse de uma imagem
   - Normalizar e pré-processar dados de imagens
   - Construir classificadores para reconhecimento de faces
   - Extrair regiões do rosto humano baseado em marcos faciais
   - Analisar diferentes condições de cada componente do rosto humano
   - Usar OpenCV
- [ ] **Processamento de Linguagem Natural**:
   - Processamento de língua natural (PLN) é uma subárea da inteligência artificial e da linguística que estuda os problemas da geração e compreensão automática de línguas humanas naturais.
   - Análise de Sentimento
   - Criar visualizações para facilitar a análise de dados textuais
   - Conhecer as bibliotecas NLTK e Scikit-Learn
   - Normalizar textos
   - Usar TF-IDF e Ngrams para melhorar a classificação
   - Utilizar o SKlearn
   - Utilizar Regex em PLN
   - Conhecer o Word2Vec
   - Combinar vetores de palavras para representar textos e classificá-los
## Habilidade Auxiliar: Cloud, Big Data e Sistemas 
- [ ] **Big Data e Engenharia de Dados**:
   - Big data é a área do conhecimento que estuda como tratar, analisar e obter informações a partir de conjuntos de dados grandes demais para serem analisados por sistemas tradicionais.
   - Engenharia de Dados envolve o desenvolvimento e organização de processos para coleta, armazenamento e transformação de dados em grande escala.
   - Criar um pipeline de dados
   - Conhecer o Apache Airflow
   - Conhecer o Apache Spark
   - Conhecer o conceito de Data Lake
   - Interagir com servidores na nuvem
   - Criar aplicações Spark
- [ ] **Cloud - Fundamentos**:
   - Cloud, ou computação em nuvem é a distribuição de serviços de computação pela Internet usando um modelo de preço pago conforme o uso. Uma nuvem é composta de vários recursos de computação, que abrangem desde os próprios computadores (ou instâncias, na terminologia de nuvem) até redes, armazenamento, bancos de dados e o que estiver em torno deles. Ou seja, tudo o que normalmente é necessário para montar o equivalente a uma sala de servidores, ou mesmo um data center completo, estará pronto para ser utilizado, configurado e executado.
   - Conhecer a diferença entre IaaS, PaaS e SaaS
   - Conhecer os maiores provedores de cloud
   - Especializar-se em algum provedor
- [ ] **Git e GitHub - Fundamentos**:
   - Git é um sistema de controle de versão distribuído gratuito e de código aberto projetado para lidar com tudo, desde projetos pequenos a muito grandes com velocidade e eficiência.
   - GitHub é um serviço de hospedagem para desenvolvimento de software e controle de versão usando Git.
   - Criar um repositório
   - Clonar um repositório
   - Fazer commit, push e pull de e para o repositório
   - Reverter um commit
   - Criar branches e pul requests
   - Lidar com merge e conflitos
- [ ] **Linux - Fundamentos**:
   - Linux é um termo popularmente empregado para se referir a sistemas operacionais que utilizam o Kernel Linux. As distribuições incluem o Kernel Linux, além de softwares de sistema e bibliotecas.
   - Conhecer o sistema de diretórios do Linux
   - Compactar e descompactar arquivos
   - Editar arquivos no console com o VI
   - Gerenciar os processos rodando na máquina
   - Conhecer as variáveis de ambiente e o PATH
   - Gerenciar pacotes
   - Realizar comunicação remota com o SSH e SCP
## Habilidade Auxiliar: Business 
- [ ] **Gestão de Processos de Negócios**:
   - A Gestão de Processos de Negócios (BPM) é a um disciplina que utiliza vários métodos para descobrir, modelar, analisar, medir, melhorar, otimizar e automatizar processos de negócios.
- [ ] **Business Intelligence (BI) - Fundamentos**:
   - Business Intelligence é um conjunto de teorias, metodologias, processos e tecnologias que possibilitam a transformação dos dados “crus” em informações extremamente relevantes para tomada de decisão de uma empresa.
   - Conhecer o processo de ETL
   - Realizar a modelagem e estruturação de tabelas em um Data Warehouse
   - Criar visualizações que façam sentido
   - Conhecer o PowerBI
- [ ] **Storytelling com dados**:
   - Storytelling é uma forma de contar histórias que engajam e chamam a atenção da pessoa que está ouvindo. Dentro da análise de dados, é algo muito importante para passar as informações ao receptor de modo que o mesmo compreenda não apenas os dados, mas também todo o contexto.
- [ ] **Excel**:
   - O Microsoft Excel é um editor de planilhas produzido pela Microsoft com ferramentas de cálculo e de construção de tabelas.
   - Realizar as operações matemáticas básicas com seus operadores (soma, subtração, multiplicação e divisão)
   - Conhecer as principais fórmulas, como 'MÉDIA' (AVERAGE), 'ARRED' (ROUND), 'MÁXIMO' (MAX), 'MÍNIMO' (MIN), etc
   - Realizar buscas em colunas com a função 'PROCV'
   - Criar gráficos
- [ ] **Habilidades de comunicação**:
   - Um bom nível de comunicação facilita o atingimento de objetivos, resolução de problemas, além de aumentar a produtividade, porque cada profissional saberá exatamente o que se espera dele e transmitir com clareza suas ideias.
